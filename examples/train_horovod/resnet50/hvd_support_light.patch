diff --git a/official/vision/image_classification/classifier_trainer.py b/official/vision/image_classification/classifier_trainer.py
index ab6fbaea9..f0f2cb2c5 100644
--- a/official/vision/image_classification/classifier_trainer.py
+++ b/official/vision/image_classification/classifier_trainer.py
@@ -37,6 +37,14 @@ from official.vision.image_classification.efficientnet import efficientnet_model
 from official.vision.image_classification.resnet import common
 from official.vision.image_classification.resnet import resnet_model
 
+global is_mpi
+try:
+    import horovod.tensorflow.keras as hvd
+    hvd.init()
+    is_mpi = hvd.size()
+except ImportError:
+    is_mpi = 0
+    print("No MPI horovod support, this is running in no-MPI mode!")
 
 def get_models() -> Mapping[str, tf.keras.Model]:
   """Returns the mapping from model type name to Keras model."""
@@ -289,6 +297,12 @@ def train_and_eval(
   """Runs the train and eval path using compile/fit."""
   logging.info('Running train and eval.')
 
+  if is_mpi:
+    gpus = tf.config.experimental.list_physical_devices('XPU')
+    for gpu in gpus:
+      tf.config.experimental.set_memory_growth(gpu, True)
+    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'XPU')
+
   distribute_utils.configure_cluster(params.runtime.worker_hosts,
                                      params.runtime.task_index)
 
@@ -299,7 +313,7 @@ def train_and_eval(
       num_gpus=params.runtime.num_gpus,
       tpu_address=params.runtime.tpu)
 
-  strategy_scope = distribute_utils.get_strategy_scope(strategy)
+  #strategy_scope = distribute_utils.get_strategy_scope(strategy)
 
   logging.info('Detected %d devices.',
                strategy.num_replicas_in_sync if strategy else 1)
@@ -324,56 +338,74 @@ def train_and_eval(
 
   logging.info('Global batch size: %d', train_builder.global_batch_size)
 
-  with strategy_scope:
-    model_params = params.model.model_params.as_dict()
-    model = get_models()[params.model.name](**model_params)
-    learning_rate = optimizer_factory.build_learning_rate(
-        params=params.model.learning_rate,
-        batch_size=train_builder.global_batch_size,
-        train_epochs=train_epochs,
-        train_steps=train_steps)
-    optimizer = optimizer_factory.build_optimizer(
-        optimizer_name=params.model.optimizer.name,
-        base_learning_rate=learning_rate,
-        params=params.model.optimizer.as_dict(),
-        model=model)
-    optimizer = performance.configure_optimizer(
-        optimizer,
-        use_float16=train_builder.dtype == 'float16',
-        loss_scale=get_loss_scale(params))
-
-    metrics_map = _get_metrics(one_hot)
-    metrics = [metrics_map[metric] for metric in params.train.metrics]
-    steps_per_loop = train_steps if params.train.set_epoch_loop else 1
-
-    if one_hot:
-      loss_obj = tf.keras.losses.CategoricalCrossentropy(
-          label_smoothing=params.model.loss.label_smoothing)
-    else:
-      loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()
-    model.compile(
-        optimizer=optimizer,
-        loss=loss_obj,
-        metrics=metrics,
-        steps_per_execution=steps_per_loop)
-
-    initial_epoch = 0
-    if params.train.resume_checkpoint:
-      initial_epoch = resume_from_checkpoint(
-          model=model, model_dir=params.model_dir, train_steps=train_steps)
+  model_params = params.model.model_params.as_dict()
+  model = get_models()[params.model.name](**model_params)
+  learning_rate = optimizer_factory.build_learning_rate(
+    params=params.model.learning_rate,
+    batch_size=train_builder.global_batch_size * hvd.size(),
+    train_epochs=train_epochs,
+    train_steps=train_steps)
+  optimizer = optimizer_factory.build_optimizer(
+    optimizer_name=params.model.optimizer.name,
+    base_learning_rate=learning_rate,
+    params=params.model.optimizer.as_dict(),
+    model=model)
+  optimizer = performance.configure_optimizer(
+    optimizer,
+    use_float16=train_builder.dtype == 'float16',
+    loss_scale=get_loss_scale(params))
+
+  metrics_map = _get_metrics(one_hot)
+  metrics = [metrics_map[metric] for metric in params.train.metrics]
+  steps_per_loop = train_steps if params.train.set_epoch_loop else 1
 
-    callbacks = custom_callbacks.get_callbacks(
-        model_checkpoint=params.train.callbacks.enable_checkpoint_and_export,
-        include_tensorboard=params.train.callbacks.enable_tensorboard,
-        time_history=params.train.callbacks.enable_time_history,
-        track_lr=params.train.tensorboard.track_lr,
-        write_model_weights=params.train.tensorboard.write_model_weights,
-        initial_step=initial_epoch * train_steps,
-        batch_size=train_builder.global_batch_size,
-        log_steps=params.train.time_history.log_steps,
-        model_dir=params.model_dir,
-        backup_and_restore=params.train.callbacks.enable_backup_and_restore)
+  if one_hot:
+    loss_obj = tf.keras.losses.CategoricalCrossentropy(
+      label_smoothing=params.model.loss.label_smoothing)
+  else:
+    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()
 
+  hvd_optimizer = hvd.DistributedOptimizer(optimizer, num_groups=1)
+  model.compile(
+    optimizer=hvd_optimizer,
+    loss=loss_obj,
+    metrics=metrics,
+    steps_per_execution=steps_per_loop)
+
+  initial_epoch = 0
+  if params.train.resume_checkpoint:
+    initial_epoch = resume_from_checkpoint(
+      model=model, model_dir=params.model_dir, train_steps=train_steps)
+
+  # Add broadcast callback for rank0
+  callbacks = []
+
+  if hvd.local_rank() == 0:
+    callbacks = custom_callbacks.get_callbacks(
+      model_checkpoint=params.train.callbacks.enable_checkpoint_and_export,
+      include_tensorboard=params.train.callbacks.enable_tensorboard,
+      time_history=params.train.callbacks.enable_time_history,
+      track_lr=params.train.tensorboard.track_lr,
+      write_model_weights=params.train.tensorboard.write_model_weights,
+      initial_step=initial_epoch * train_steps,
+      batch_size=train_builder.global_batch_size,
+      log_steps=params.train.time_history.log_steps,
+      model_dir=params.model_dir,
+      backup_and_restore=params.train.callbacks.enable_backup_and_restore)
+  else:
+    callbacks = custom_callbacks.get_callbacks(
+      model_checkpoint=False,
+      include_tensorboard=params.train.callbacks.enable_tensorboard,
+      time_history=params.train.callbacks.enable_time_history,
+      track_lr=params.train.tensorboard.track_lr,
+      write_model_weights=params.train.tensorboard.write_model_weights,
+      initial_step=initial_epoch * train_steps,
+      batch_size=train_builder.global_batch_size,
+      log_steps=params.train.time_history.log_steps,
+      model_dir=params.model_dir,
+      backup_and_restore=params.train.callbacks.enable_backup_and_restore)
+
+  callbacks.append(hvd.callbacks.BroadcastGlobalVariablesCallback(0))
   serialize_config(params=params, model_dir=params.model_dir)
 
   if params.evaluation.skip_eval:
diff --git a/official/vision/image_classification/dataset_factory.py b/official/vision/image_classification/dataset_factory.py
index a0458eccc..e6dfb39f6 100644
--- a/official/vision/image_classification/dataset_factory.py
+++ b/official/vision/image_classification/dataset_factory.py
@@ -29,6 +29,7 @@ import tensorflow_datasets as tfds
 from official.modeling.hyperparams import base_config
 from official.vision.image_classification import augment
 from official.vision.image_classification import preprocessing
+import horovod.tensorflow as hvd
 
 AUGMENTERS = {
     'autoaugment': augment.AutoAugment,
@@ -207,7 +208,7 @@ class DatasetBuilder:
   def num_steps(self) -> int:
     """The number of steps (batches) to exhaust this dataset."""
     # Always divide by the global batch size to get the correct # of steps
-    return self.num_examples // self.global_batch_size
+    return self.num_examples // (self.global_batch_size * hvd.size())
 
   @property
   def dtype(self) -> tf.dtypes.DType:
@@ -403,14 +404,10 @@ class DatasetBuilder:
     Returns:
       A TensorFlow dataset outputting batched images and labels.
     """
-    if (self.config.builder != 'tfds' and self.input_context and
-        self.input_context.num_input_pipelines > 1):
-      dataset = dataset.shard(self.input_context.num_input_pipelines,
-                              self.input_context.input_pipeline_id)
+    if self.is_training:
+      dataset = dataset.shard(hvd.size(), hvd.rank())
       logging.info(
-          'Sharding the dataset: input_pipeline_id=%d '
-          'num_input_pipelines=%d', self.input_context.num_input_pipelines,
-          self.input_context.input_pipeline_id)
+          'Sharding the dataset: total size: %d ', hvd.size(), " local rank: %d ", hvd.rank())
 
     if self.is_training and self.config.builder == 'records':
       # Shuffle the input files.
diff --git a/official/vision/image_classification/learning_rate.py b/official/vision/image_classification/learning_rate.py
index 72f7e9518..e7edd90a2 100644
--- a/official/vision/image_classification/learning_rate.py
+++ b/official/vision/image_classification/learning_rate.py
@@ -22,10 +22,12 @@ from typing import Any, Mapping, Optional
 
 import numpy as np
 import tensorflow as tf
+from tensorflow.python.util.tf_export import keras_export
 
 BASE_LEARNING_RATE = 0.1
 
 
+@tf.keras.utils.register_keras_serializable(package='Custom', name='WarmupDeacySchedule')
 class WarmupDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
   """A wrapper for LearningRateSchedule that includes warmup steps."""
 
@@ -66,10 +68,11 @@ class WarmupDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
     return lr
 
   def get_config(self) -> Mapping[str, Any]:
-    config = self._lr_schedule.get_config()
+    config = {}
     config.update({
         "warmup_steps": self._warmup_steps,
         "warmup_lr": self._warmup_lr,
+        "lr_schedule": self._lr_schedule,
     })
     return config
 
